{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52708b7",
   "metadata": {},
   "source": [
    "Below is the basic example of Dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.utils.dates import days_ago\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "\n",
    "dag = DAG(\n",
    "        dag_id = \"testing_dag\",\n",
    "        schedule_interval = \"@daily\",\n",
    "        start_date = days_ago(1)\n",
    "        )\n",
    "\n",
    "task1 = BashOperator(\n",
    "        task_id = \"task1\",\n",
    "        bash_command = \"echo hello\",\n",
    "        dag = dag\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973bc552",
   "metadata": {},
   "source": [
    "### How to set precendencies between different tasks\n",
    "\n",
    "Below code will run the tasks(1,2,3) in series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.utils.dates import days_ago\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "\n",
    "dag = DAG(\n",
    "        dag_id = \"testing_dag\",\n",
    "        schedule_interval = \"@daily\",\n",
    "        start_date = days_ago(1)\n",
    "        )\n",
    "\n",
    "task1 = BashOperator(\n",
    "        task_id = \"task1\",\n",
    "        bash_command = \"echo hello\",\n",
    "        dag = dag\n",
    "        )\n",
    "\n",
    "\n",
    "task2 = BashOperator(\n",
    "        task_id = \"task2\",\n",
    "        bash_command = \"echo task2\",\n",
    "        dag = dag\n",
    "        )\n",
    "\n",
    "task3 = BashOperator(\n",
    "        task_id = \"task3\",\n",
    "        bash_command = \"echo task3\",\n",
    "        dag = dag\n",
    "        )\n",
    "\n",
    "task1 >> task2 >> task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053cbd7",
   "metadata": {},
   "source": [
    "If you want to run the two tasks in parallel then you've to put them in a list.\n",
    "\n",
    "Below will run the task2 and task3 in parallel after task1\n",
    "\n",
    "```python\n",
    "task1 >> [task2, task3]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fa5d4d",
   "metadata": {},
   "source": [
    "### Lifecycle of a task\n",
    "\n",
    "* Scheduled - Up for execution or ready for execution\n",
    "* Skipped - for ex - I'm reading a file and if the file has something then schedule it else skip it and schedule the next task\n",
    "* upstream_failed - if the parent task is failed then a task will be marked as upstream_failed.\n",
    "* failed - Task that is failed\n",
    "* Running - Currently running task\n",
    "* Success - Task executed successfully\n",
    "* up_for_retry - failed task is getting rerun if retry>1 is provided\n",
    "\n",
    "```python\n",
    "task1 >> [task2, task3]\n",
    "```\n",
    "Let's say I want to do something like following:\n",
    "\n",
    "```\n",
    "if task1 == success:\n",
    "  then:\n",
    "    execute task2\n",
    "  else:\n",
    "    execute task3\n",
    "```\n",
    "\n",
    "In the above cases we've to use the trigger_rule, there are various trigger rules:\n",
    "\n",
    "Default trigger_rule is all_success\n",
    "\n",
    "* all_success - all the parents are success\n",
    "* all_failed - all the parents are failed\n",
    "* all_done - All the parents have been attempted to be executed or triggerd irrespective of fail or success\n",
    "* one_failed - `[t1, t2] >> t3` In this case either t1 or t2 gets failed then only t3 will be executed.\n",
    "* one_success - `[t1, t2] >> t3` In this case either t1 or t2 gets successful then only t3 will be executed.\n",
    "* none_failed - all of the parents are either success or skipped\n",
    "* none_failed_or_skipped - atleast one parent has ssucceeded\n",
    "* none_skipped - none of the parents are skipped\n",
    "* dummy - on it own will\n",
    "\n",
    "Below is the code for scenerio `all_failed` on task:\n",
    "\n",
    "```python\n",
    "from airflow import DAG\n",
    "from airflow.utils.dates import days_ago\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "\n",
    "dag = DAG(\n",
    "        dag_id = \"testing_dag\",\n",
    "        schedule_interval = \"@daily\",\n",
    "        start_date = days_ago(1)\n",
    "        )\n",
    "\n",
    "task1 = BashOperator(\n",
    "        task_id = \"task1\",\n",
    "        bash_command = \"echo hello && exit 1\",\n",
    "        dag = dag\n",
    "        )\n",
    "\n",
    "\n",
    "task2 = BashOperator(\n",
    "        task_id = \"task2\",\n",
    "        bash_command = \"echo task2\",\n",
    "        dag = dag\n",
    "        )\n",
    "\n",
    "task3 = BashOperator(\n",
    "        task_id = \"task3\",\n",
    "        bash_command = \"echo task3\",\n",
    "        dag = dag,\n",
    "        trigger_rule = \"all_failed\"\n",
    "        )\n",
    "\n",
    "task1 >> [task2, task3]\n",
    "```\n",
    "\n",
    "### Creating custom Operators and HTTPsensors\n",
    "\n",
    "Please refer to the below code:\n",
    "\n",
    "```python\n",
    "from airflow import DAG\n",
    "from airflow.utils.dates import days_ago\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from airflow.models import BaseOperator\n",
    "from airflow.utils.decorators import apply_defaults\n",
    "from airflow.sensors.http_sensor import HttpSensor\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Below code is responsible for creating your own operator\n",
    "\"\"\"\n",
    "class MyOperator(BaseOperator):\n",
    "    @apply_defaults\n",
    "    def __init__(self, name, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.name = name\n",
    "\n",
    "    def execute(self, context):\n",
    "        message = f\"Hello {self.name}\"\n",
    "        print(message)\n",
    "        return message\n",
    "\n",
    "dag = DAG(\n",
    "        dag_id = \"testing_dag\",\n",
    "        schedule_interval = \"@daily\",\n",
    "        start_date = days_ago(1)\n",
    "        )\n",
    "\n",
    "task1 = BashOperator(\n",
    "        task_id = \"task1\",\n",
    "        bash_command = \"echo hello && exit 1\",\n",
    "        dag = dag\n",
    "        )\n",
    "\n",
    "\n",
    "task2 = BashOperator(\n",
    "        task_id = \"task2\",\n",
    "        bash_command = \"echo task2\",\n",
    "        dag = dag\n",
    "        )\n",
    "\n",
    "task3 = BashOperator(\n",
    "        task_id = \"task3\",\n",
    "        bash_command = \"echo task3\",\n",
    "        dag = dag,\n",
    "        trigger_rule = \"all_failed\"\n",
    "        )\n",
    "\n",
    "task4 = MyOperator(\n",
    "        name = \"Tushar\",\n",
    "        task_id = \"task4\",\n",
    "        dag =dag,\n",
    "        trigger_rule = \"one_success\"\n",
    "        )\n",
    "\"\"\"\n",
    "creating a http sensor, It will check the service running\n",
    "on a host and a particular port with endpoint as '/'\n",
    "make sure to configure the my_http_con in airflow ui connections\n",
    "\"\"\"\n",
    "sensor = HttpSensor(\n",
    "        task_id = \"sensor\",\n",
    "        endpoint = \"/\",\n",
    "        http_conn_id = \"my_http_con\",\n",
    "        dag = dag,\n",
    "        retries = 20,\n",
    "        retry_delay = timedelta(seconds=20)\n",
    "        )\n",
    "\n",
    "sensor >> task1 >> [task2, task3] >> task4\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a969c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
